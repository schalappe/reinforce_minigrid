# Default configuration for PPO training on MiniGrid Maze

environment:
  seed: 42

training:
  total_timesteps: 1000000
  steps_per_update: 2048

ppo:
  learning_rate: 3.0e-4
  gamma: 0.99
  lambda: 0.95  # Corresponds to lambda_gae in the dataclass
  clip_param: 0.2
  entropy_coef: 0.01
  vf_coef: 0.5   # Corresponds to value_coef in the dataclass
  epochs: 10
  batch_size: 64

logging:
  log_interval: 1
  save_interval: 10
  save_path: "models/ppo_maze"
  load_path: null # Set to a path like "models/ppo_maze" to load a pre-trained model
