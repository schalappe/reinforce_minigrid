# Default configuration for PPO training on MiniGrid Maze

environment:
  seed: 42

training:
  total_timesteps: 3000000
  steps_per_update: 128 # Smaller rollouts work better with more envs
  num_envs: 8 # More parallel environments for better sample efficiency

ppo:
  learning_rate: 2.5e-4 # Standard PPO learning rate
  gamma: 0.99
  lambda: 0.95
  clip_param: 0.2
  entropy_coef: 0.01
  vf_coef: 0.5
  epochs: 4 # Fewer epochs with smaller rollouts
  batch_size: 256 # Larger batches for stable gradients
  max_grad_norm: 0.5 # Global gradient clipping
  use_lr_annealing: true # Linear decay to 0
  use_value_clipping: false # Can hurt performance per ablations

logging:
  log_interval: 1
  save_interval: 10
  save_path: "models/ppo_maze"
  load_path: null
