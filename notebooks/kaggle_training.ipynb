{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Reinforcement Learning Training on Kaggle (GPU-Optimized)\n\nThis notebook trains **PPO** and **Rainbow DQN** agents on MiniGrid maze environments.\n\n## Key Optimizations for GPU Utilization\n\n| Change | Before | After | Impact |\n|--------|--------|-------|--------|\n| DQN batch_size | 32 | 256 | 8x more GPU work per step |\n| DQN train_freq | 4 | 1 | Train every step |\n| PPO batch_size | 64 | 512 | 8x more GPU work per step |\n| num_envs | 4 | 16 | More parallel data |\n| Dataset prefetch | No | Yes | Overlaps I/O with compute |\n\n## Setup Instructions\n\n1. **Enable GPU**: Settings > Accelerator > **GPU P100** (recommended)\n2. **Enable Internet**: Settings > Internet > On (for cloning repo)\n3. **Run all cells** in order\n\n## Training Time Estimates (P100 GPU, Optimized)\n\n| Algorithm | Timesteps | Estimated Time |\n|-----------|-----------|----------------|\n| PPO       | 500K      | ~30-45 min     |\n| PPO       | 1M        | ~1-1.5 hours   |\n| DQN       | 500K      | ~45-60 min     |\n| DQN       | 1M        | ~1.5-2 hours   |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (TensorFlow is pre-installed on Kaggle)\n",
    "# Using specific versions compatible with Kaggle's Python 3.10 environment\n",
    "!pip install -q \\\n",
    "    minigrid==3.0.0 \\\n",
    "    gymnasium>=1.1.1 \\\n",
    "    tensorflow-probability \\\n",
    "    pydantic-settings>=2.7.0 \\\n",
    "    loguru>=0.7.3 \\\n",
    "    imageio>=2.37.0 \\\n",
    "    rich>=13.3.3 \\\n",
    "    pyyaml>=6.0.2 \\\n",
    "    click>=8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify TensorFlow GPU support\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Enable memory growth to avoid OOM\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Memory growth enabled for {len(gpus)} GPU(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Clone Repository\n",
    "\n",
    "**Option A**: Clone from GitHub (if public repo)\n",
    "\n",
    "**Option B**: Upload as Kaggle Dataset (for private repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPTION A: Clone from GitHub ===\n",
    "# Uncomment and modify the URL if your repo is public\n",
    "\n",
    "# !git clone https://github.com/YOUR_USERNAME/reinforce_minigrid.git\n",
    "# %cd reinforce_minigrid\n",
    "\n",
    "# === OPTION B: Upload as Kaggle Dataset ===\n",
    "# 1. Create a new Kaggle Dataset with your project files\n",
    "# 2. Add the dataset to this notebook via \"Add Data\"\n",
    "# 3. Uncomment below:\n",
    "\n",
    "# !cp -r /kaggle/input/reinforce-minigrid/* /kaggle/working/\n",
    "# %cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPTION C: Upload directly (for testing) ===\n",
    "# Upload your project as a zip file and extract it\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if running on Kaggle\n",
    "IS_KAGGLE = Path('/kaggle').exists()\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    WORK_DIR = Path('/kaggle/working')\n",
    "    # List available input datasets\n",
    "    print(\"Available datasets:\")\n",
    "    !ls -la /kaggle/input/\n",
    "else:\n",
    "    # Local development\n",
    "    WORK_DIR = Path('.').resolve()\n",
    "    \n",
    "print(f\"\\nWorking directory: {WORK_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Project Setup (Manual Upload Alternative)\n",
    "\n",
    "If you can't clone/use datasets, this cell creates the minimal project structure.\n",
    "\n",
    "**Skip this section if you cloned the repo successfully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure (only if needed)\n",
    "import os\n",
    "\n",
    "dirs_to_create = [\n",
    "    'configs',\n",
    "    'models',\n",
    "    'maze/envs',\n",
    "    'reinforce/core',\n",
    "    'reinforce/ppo',\n",
    "    'reinforce/dqn',\n",
    "    'reinforce/config',\n",
    "]\n",
    "\n",
    "for dir_path in dirs_to_create:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    # Create __init__.py files\n",
    "    init_path = os.path.join(dir_path, '__init__.py')\n",
    "    if not os.path.exists(init_path):\n",
    "        open(init_path, 'w').close()\n",
    "\n",
    "print(\"Directory structure created!\")\n",
    "!find . -type d -name '__pycache__' -prune -o -type f -name '*.py' -print | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Configuration\n",
    "\n",
    "Kaggle-optimized training settings (reduced for GPU memory and time constraints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GPU-Optimized Training Configuration for Kaggle T4 x2\n# Key changes: larger batch sizes, more envs, train_freq=1\n\nKAGGLE_CONFIG = \"\"\"\n# Kaggle-optimized configuration for T4 x2 GPUs\n# Maximizes GPU utilization with larger batches and vectorized operations\n\nalgorithm: ppo\n\nenvironment:\n  seed: 42\n\ntraining:\n  total_timesteps: 1000000\n  steps_per_update: 256\n  num_envs: 16  # Increased for more parallel data collection\n\n# PPO hyperparameters - optimized for GPU throughput\nppo:\n  learning_rate: 2.5e-4\n  gamma: 0.99\n  lambda: 0.95\n  clip_param: 0.2\n  entropy_coef: 0.01\n  vf_coef: 0.5\n  epochs: 4\n  batch_size: 512  # Increased for better GPU utilization\n  max_grad_norm: 0.5\n  use_lr_annealing: true\n  use_value_clipping: false\n\n# Rainbow DQN - GPU-optimized settings\ndqn:\n  learning_rate: 6.25e-5\n  gamma: 0.99\n  n_step: 3\n  num_atoms: 51\n  v_min: -10.0\n  v_max: 10.0\n  buffer_size: 100000\n  batch_size: 256  # CRITICAL: 8x larger for GPU utilization\n  target_update_freq: 2000  # More frequent with larger batches\n  learning_starts: 5000  # Start learning sooner\n  train_freq: 1  # Train every step (was 4)\n  priority_alpha: 0.6\n  priority_beta_start: 0.4\n  priority_beta_frames: 100000\n  use_noisy: true\n  use_dueling: true\n  use_double: true\n  use_per: true\n\n# RND for intrinsic motivation (PPO only)\nrnd:\n  enabled: true\n  feature_dim: 512\n  learning_rate: 1e-4\n  intrinsic_reward_scale: 1.0\n  update_proportion: 0.25\n  intrinsic_reward_coef: 0.5\n\n# Exploration strategies (PPO only)\nexploration:\n  use_epsilon_greedy: true\n  epsilon_start: 0.3\n  epsilon_end: 0.01\n  epsilon_decay_steps: 300000\n  use_ucb: true\n  ucb_coefficient: 0.5\n  use_adaptive_entropy: true\n  target_entropy_ratio: 0.5\n  entropy_lr: 0.01\n  min_entropy_coef: 0.001\n  max_entropy_coef: 0.1\n\nlogging:\n  log_interval: 1\n  save_interval: 10\n  save_path: \"models/kaggle_model\"\n  load_path: null\n\"\"\"\n\n# Write config file\nwith open('configs/kaggle_training.yaml', 'w') as f:\n    f.write(KAGGLE_CONFIG)\n\nprint(\"GPU-optimized configuration saved!\")\nprint(\"\\nKey optimizations:\")\nprint(\"  - DQN batch_size: 256 (was 32)\")\nprint(\"  - DQN train_freq: 1 (was 4)\")\nprint(\"  - num_envs: 16 (was 4)\")\nprint(\"  - Multi-GPU: Auto-enabled via MirroredStrategy\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all imports work\n",
    "try:\n",
    "    import gymnasium\n",
    "    import minigrid\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_probability as tfp\n",
    "    import keras\n",
    "    from pydantic import BaseModel\n",
    "    import yaml\n",
    "    from loguru import logger\n",
    "    \n",
    "    print(\"All imports successful!\")\n",
    "    print(f\"  - gymnasium: {gymnasium.__version__}\")\n",
    "    print(f\"  - tensorflow: {tf.__version__}\")\n",
    "    print(f\"  - keras: {keras.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please run the dependency installation cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify project modules are importable\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "try:\n",
    "    from maze.envs import BaseMaze, EasyMaze, MediumMaze, HardMaze\n",
    "    from reinforce.factory import create_agent\n",
    "    from reinforce.config.config_loader import load_config\n",
    "    \n",
    "    print(\"Project modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Project import error: {e}\")\n",
    "    print(\"Make sure the project files are in the working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test environment creation\n",
    "from minigrid.wrappers import RGBImgPartialObsWrapper, ImgObsWrapper\n",
    "from maze.envs import BaseMaze\n",
    "\n",
    "env = BaseMaze(render_mode=\"rgb_array\")\n",
    "env = RGBImgPartialObsWrapper(env)\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "obs, _ = env.reset(seed=42)\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "env.close()\n",
    "\n",
    "print(\"\\nEnvironment test passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 6. Train PPO Agent (GPU-Optimized)\n\n**Estimated time**: ~30-45 min for 500K timesteps on P100 GPU\n\nKey optimizations applied:\n- **batch_size=512** (8x larger than default 64)\n- **steps_per_update=256** (more data per update)\n- **num_envs=16** (more parallel environments)\n- **Dataset prefetching**: Overlaps data loading with GPU compute"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# PPO Training with GPU-optimized settings\n# Using 16 envs and batch_size=512 for maximum GPU utilization\n!python -m reinforce.train \\\n    --config configs/kaggle_training.yaml \\\n    --algorithm ppo \\\n    --total-timesteps 500000 \\\n    --num-envs 16 \\\n    --batch-size 512 \\\n    --save-path models/kaggle_ppo"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved PPO models\n",
    "!ls -la models/kaggle_ppo* 2>/dev/null || echo \"No PPO models found yet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 7. Train Rainbow DQN Agent (GPU-Optimized)\n\n**Estimated time**: ~45-60 min for 500K timesteps on P100 GPU\n\nKey optimizations applied:\n- **batch_size=256** (8x larger than default 32)\n- **train_freq=1** (train every step, not every 4)\n- **num_envs=16** (more parallel environments)\n- **Vectorized buffer**: Batch transition storage"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Rainbow DQN Training with GPU-optimized settings\n# batch_size=256, train_freq=1, 16 envs for maximum GPU utilization\n!python -m reinforce.train \\\n    --config configs/kaggle_training.yaml \\\n    --algorithm dqn \\\n    --total-timesteps 500000 \\\n    --num-envs 16 \\\n    --buffer-size 100000 \\\n    --learning-starts 5000 \\\n    --save-path models/kaggle_dqn"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saved DQN models\n",
    "!ls -la models/kaggle_dqn* 2>/dev/null || echo \"No DQN models found yet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Extended Training (Optional)\n",
    "\n",
    "If you have time remaining, continue training with more timesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended PPO training (1M timesteps)\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python -m reinforce.train \\\n",
    "#     --config configs/kaggle_training.yaml \\\n",
    "#     --algorithm ppo \\\n",
    "#     --total-timesteps 1000000 \\\n",
    "#     --num-envs 4 \\\n",
    "#     --save-path models/kaggle_ppo_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended DQN training (1M timesteps)\n",
    "# Uncomment to run:\n",
    "\n",
    "# !python -m reinforce.train \\\n",
    "#     --config configs/kaggle_training.yaml \\\n",
    "#     --algorithm dqn \\\n",
    "#     --total-timesteps 1000000 \\\n",
    "#     --num-envs 4 \\\n",
    "#     --save-path models/kaggle_dqn_extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Visualize Trained Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find the latest saved models\nimport glob\nfrom pathlib import Path\n\ndef find_latest_model(prefix: str, algorithm: str) -> str | None:\n    \"\"\"Find the most recent model checkpoint.\"\"\"\n    if algorithm == 'ppo':\n        pattern = f\"{prefix}*_policy.keras\"\n    else:\n        # ##>: DQN saves _online.keras and _target.keras, not _q_network.keras.\n        pattern = f\"{prefix}*_online.keras\"\n    \n    files = glob.glob(pattern)\n    if not files:\n        return None\n    \n    # ##>: Get the latest by modification time.\n    latest = max(files, key=lambda x: Path(x).stat().st_mtime)\n    \n    # ##>: Strip the correct suffix based on what was found.\n    if latest.endswith('_policy.keras'):\n        return latest.rsplit('_policy.keras', 1)[0]\n    elif latest.endswith('_online.keras'):\n        return latest.rsplit('_online.keras', 1)[0]\n    elif latest.endswith('_target.keras'):\n        return latest.rsplit('_target.keras', 1)[0]\n    return None\n\nppo_model = find_latest_model('models/kaggle_ppo', 'ppo')\ndqn_model = find_latest_model('models/kaggle_dqn', 'dqn')\n\nprint(f\"Latest PPO model: {ppo_model}\")\nprint(f\"Latest DQN model: {dqn_model}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PPO agent (creates GIF)\n",
    "if ppo_model:\n",
    "    !python -m reinforce.visualize \\\n",
    "        --model-prefix {ppo_model} \\\n",
    "        --algorithm ppo \\\n",
    "        --level easy \\\n",
    "        --episodes 3 \\\n",
    "        --output models/ppo_demo.gif\n",
    "else:\n",
    "    print(\"No PPO model found. Train first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize DQN agent (creates GIF)\n",
    "if dqn_model:\n",
    "    !python -m reinforce.visualize \\\n",
    "        --model-prefix {dqn_model} \\\n",
    "        --algorithm dqn \\\n",
    "        --level easy \\\n",
    "        --episodes 3 \\\n",
    "        --output models/dqn_demo.gif\n",
    "else:\n",
    "    print(\"No DQN model found. Train first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GIFs in notebook\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "\n",
    "for gif_path in ['models/ppo_demo.gif', 'models/dqn_demo.gif']:\n",
    "    if Path(gif_path).exists():\n",
    "        print(f\"\\n{gif_path}:\")\n",
    "        display(Image(filename=gif_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Download Models\n",
    "\n",
    "Save your trained models before the Kaggle session expires!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved models\n",
    "!echo \"=== All Saved Models ===\"\n",
    "!ls -lah models/*.keras 2>/dev/null || echo \"No .keras models found\"\n",
    "!echo \"\"\n",
    "!echo \"=== Total Size ===\"\n",
    "!du -sh models/ 2>/dev/null || echo \"models/ directory not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip archive for easy download\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "archive_name = f'trained_models_{timestamp}'\n",
    "\n",
    "# Create zip of models directory\n",
    "shutil.make_archive(archive_name, 'zip', '.', 'models')\n",
    "\n",
    "print(f\"Archive created: {archive_name}.zip\")\n",
    "!ls -lh {archive_name}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle: Models in /kaggle/working/ are automatically available for download\n",
    "# Click \"Save Version\" -> \"Save & Run All\" to persist outputs\n",
    "\n",
    "print(\"To download models from Kaggle:\")\n",
    "print(\"1. Click 'Save Version' at top right\")\n",
    "print(\"2. Select 'Save & Run All (Commit)'\")\n",
    "print(\"3. After completion, go to the Output tab\")\n",
    "print(\"4. Download individual files or the zip archive\")\n",
    "print(\"\")\n",
    "print(\"Files available for download:\")\n",
    "!ls -la *.zip models/*.keras models/*.gif 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Resume Training (Next Session)\n",
    "\n",
    "To continue training in a new Kaggle session:\n",
    "\n",
    "1. Upload your saved models as a Kaggle Dataset\n",
    "2. Add the dataset to your notebook\n",
    "3. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy models from dataset to working directory (if resuming)\n",
    "# Uncomment and modify path as needed:\n",
    "\n",
    "# !cp /kaggle/input/YOUR_DATASET_NAME/models/*.keras models/\n",
    "# !ls -la models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume PPO training from checkpoint\n",
    "# Uncomment to run:\n",
    "\n",
    "# CHECKPOINT = \"models/kaggle_ppo_ts500000_stage1\"  # Adjust to your checkpoint\n",
    "\n",
    "# !python -m reinforce.train \\\n",
    "#     --config configs/kaggle_training.yaml \\\n",
    "#     --algorithm ppo \\\n",
    "#     --total-timesteps 1000000 \\\n",
    "#     --num-envs 4 \\\n",
    "#     --load-path {CHECKPOINT} \\\n",
    "#     --save-path models/kaggle_ppo_resumed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Troubleshooting\n\n### Common Issues\n\n**1. Out of Memory (OOM)**\n```bash\n# Reduce batch_size first\n--batch-size 256  # or 128\n\n# Then reduce num_envs if still OOM\n--num-envs 8\n```\n\n**2. Low GPU Utilization (< 30%)**\n```bash\n# Increase batch_size (most impactful)\n--batch-size 512  # or 1024\n\n# For DQN, ensure train_freq=1\n# (already set in kaggle_training.yaml)\n```\n\n**3. Training Too Slow**\n```bash\n# Check GPU utilization first\n!nvidia-smi\n\n# If GPU utilization is high but still slow,\n# increase batch_size to reduce overhead\n--batch-size 512\n\n# Reduce logging frequency\n--log-interval 10\n```\n\n**4. Import Errors**\n```bash\n# Reinstall dependencies\n!pip install --upgrade minigrid gymnasium tensorflow\n```\n\n**5. Session Timeout**\n- Save checkpoints frequently (--save-interval 5)\n- Use background execution: Save notebook, close tab\n- Resume from last checkpoint in new session\n\n### GPU Optimization Reference\n\n| Setting | Default | Optimized | Impact |\n|---------|---------|-----------|--------|\n| PPO batch_size | 64 | 512 | 8x GPU work |\n| DQN batch_size | 32 | 256 | 8x GPU work |\n| DQN train_freq | 4 | 1 | 4x training ops |\n| num_envs | 4 | 16 | 4x parallel data |\n| Prefetch | No | Yes | ~10-20% speed |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Monitor GPU usage during training\n# Run this in a separate cell while training to verify optimization worked\n\nprint(\"=== GPU Utilization Check ===\")\nprint(\"Target: >30% GPU utilization on P100\\n\")\n\n!nvidia-smi --query-gpu=index,name,utilization.gpu,memory.used,memory.total --format=csv\n\nprint(\"\\n=== Expected Results After Optimization ===\")\nprint(\"GPU: 30-50% utilization (was 5%)\")\nprint(\"\\nIf still low, try increasing batch_size further (512, 1024)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Summary\n\nThis notebook provides GPU-optimized training for Kaggle P100:\n\n### Optimizations Applied\n\n**Both PPO and DQN:**\n- ✅ Larger batch sizes (8x default)\n- ✅ More parallel environments (16 vs 4)\n- ✅ Dataset prefetching (overlaps I/O with compute)\n\n**DQN-specific:**\n- ✅ `train_freq=1` (train every step vs every 4)\n- ✅ Vectorized batch storage\n\n### Expected GPU Utilization\n\n| Metric | Before | After |\n|--------|--------|-------|\n| GPU utilization | 5% | 30-50% |\n| Training time | 2-3 hours | 45-60 min |\n\n**Next Steps:**\n1. Run training with optimized settings\n2. Monitor GPU with `nvidia-smi` cell\n3. Download the zip archive\n4. Use models locally with `make visualize`"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}